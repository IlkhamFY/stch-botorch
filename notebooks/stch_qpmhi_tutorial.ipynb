{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STCH-qPMHI Tutorial\n",
    "\n",
    "This notebook demonstrates the **STCH-qPMHI two-stage batch selection framework** for multi-objective Bayesian optimization.\n",
    "\n",
    "## Overview\n",
    "\n",
    "STCH-qPMHI combines:\n",
    "1. **Stage 1 (STCH Candidate Generation)**: Efficiently generates diverse candidate pool using STCH scalarization with multiple weight vectors\n",
    "2. **Stage 2 (qPMHI Batch Selection)**: Selects optimal batch by ranking candidates using Probability of Maximum Hypervolume Improvement\n",
    "\n",
    "This approach leverages gradient-based STCH optimization for exploration, combined with hypervolume-optimal batch selection via qPMHI.\n",
    "\n",
    "**Note**: This framework adapts the qPMHI algorithm from Muthyala et al. (2025) to work with STCH scalarization for continuous optimization problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "# Import STCH-qPMHI (when implementation is available)\n",
    "# from stch_botorch import optimize_stch_qpmhi, qPMHI\n",
    "# from stch_botorch.integration import STCHqPMHIAcquisition, STCHCandidateGenerator\n",
    "from stch_botorch import smooth_chebyshev\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"STCH-qPMHI Tutorial\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Problem and Initial Data\n",
    "\n",
    "We'll use a simple 2-objective problem for demonstration. In practice, STCH-qPMHI works with any continuous multi-objective optimization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple 2D input, 2-objective problem for demonstration\n",
    "def simple_multi_obj(X):\n",
    "    \"\"\"Simple 2-objective function for demonstration.\"\"\"\n",
    "    obj1 = -((X[:, 0] - 0.5) ** 2 + (X[:, 1] - 0.5) ** 2)  # Maximize (negate for minimization)\n",
    "    obj2 = -((X[:, 0] - 0.3) ** 2 + (X[:, 1] - 0.7) ** 2)\n",
    "    return torch.stack([obj1, obj2], dim=-1)\n",
    "\n",
    "# Initial data\n",
    "n_init = 8\n",
    "train_X = torch.rand(n_init, 2, dtype=torch.double)\n",
    "train_Y = simple_multi_obj(train_X)\n",
    "\n",
    "bounds = torch.stack([torch.zeros(2, dtype=torch.double), torch.ones(2, dtype=torch.double)])\n",
    "\n",
    "print(f\"Initial data: {train_X.shape[0]} points\")\n",
    "print(f\"Objectives: {train_Y.shape[1]}\")\n",
    "print(f\"Bounds: {bounds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pareto(Y):\n",
    "    \"\"\"Compute Pareto front (maximization).\"\"\"\n",
    "    if Y.shape[0] == 0:\n",
    "        return Y\n",
    "    \n",
    "    n, m = Y.shape\n",
    "    is_pareto = torch.ones(n, dtype=torch.bool, device=Y.device)\n",
    "    \n",
    "    for i in range(n):\n",
    "        if not is_pareto[i]:\n",
    "            continue\n",
    "        y_i = Y[i:i+1]\n",
    "        \n",
    "        for j in range(i+1, n):\n",
    "            if not is_pareto[j]:\n",
    "                continue\n",
    "            y_j = Y[j:j+1]\n",
    "            \n",
    "            if (y_j >= y_i).all() and (y_j > y_i).any():\n",
    "                is_pareto[i] = False\n",
    "                break\n",
    "            if (y_i >= y_j).all() and (y_i > y_j).any():\n",
    "                is_pareto[j] = False\n",
    "    \n",
    "    return Y[is_pareto]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: STCH Candidate Generation (Conceptual)\n",
    "\n",
    "In the full implementation, STCH-qPMHI uses `STCHCandidateGenerator` to:\n",
    "1. Generate multiple weight vectors (e.g., via Sobol sampling on simplex)\n",
    "2. For each weight, optimize STCH scalarization using gradient-based optimization\n",
    "3. Collect diverse candidates covering the Pareto front\n",
    "\n",
    "Here we demonstrate the concept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GP model\n",
    "model = SingleTaskGP(train_X, train_Y)\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "print(\"Model fitted successfully\")\n",
    "\n",
    "# Compute Pareto front and reference point\n",
    "pareto_Y = compute_pareto(train_Y)\n",
    "ref_point = torch.tensor([-1.0, -1.0], dtype=torch.double)  # Reference point for hypervolume\n",
    "\n",
    "print(f\"Pareto front size: {pareto_Y.shape[0]}\")\n",
    "print(f\"Reference point: {ref_point}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: qPMHI Batch Selection (Conceptual)\n",
    "\n",
    "The qPMHI algorithm (from Muthyala et al., 2025) scores each candidate by the probability that it achieves the maximum hypervolume improvement. The key insight is that qPMHI has an additive decomposition property, enabling exact batch selection via simple ranking.\n",
    "\n",
    "**Note**: The full implementation will use the `optimize_stch_qpmhi` function or `STCHqPMHIAcquisition` class. See README.md for complete usage example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using STCH-qPMHI (when implementation is available)\n",
    "# batch = optimize_stch_qpmhi(\n",
    "#     model=model,\n",
    "#     bounds=bounds,\n",
    "#     pareto_Y=pareto_Y,\n",
    "#     ref_point=ref_point,\n",
    "#     q=4,  # Batch size\n",
    "#     num_candidates=100,  # Candidate pool size\n",
    "#     stch_kwargs={\"num_weights\": 50, \"num_restarts\": 3},\n",
    "# )\n",
    "\n",
    "print(\"\\nSTCH-qPMHI Framework:\")\n",
    "print(\"1. Stage 1: STCH generates diverse candidate pool\")\n",
    "print(\"2. Stage 2: qPMHI ranks candidates and selects top-q\")\n",
    "print(\"\\nSee README.md for complete usage example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Two-Stage Framework\n",
    "\n",
    "### Why STCH-qPMHI?\n",
    "\n",
    "**STCH Stage 1 Advantages:**\n",
    "- Gradient-based optimization (efficient)\n",
    "- Theoretically proven Pareto coverage\n",
    "- No generative model required\n",
    "- Works with continuous optimization problems\n",
    "\n",
    "**qPMHI Stage 2 Advantages:**\n",
    "- Hypervolume-optimal batch selection\n",
    "- Additive decomposition enables exact selection via ranking\n",
    "- Scalable to large pools and batches\n",
    "- From Muthyala et al. (2025) - properly cited\n",
    "\n",
    "**Combined Benefits:**\n",
    "- Pareto coverage guarantees (STCH) + Hypervolume optimality (qPMHI)\n",
    "- Efficient exploration + Optimal batch selection\n",
    "- Works for continuous problems without generative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize current Pareto front\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.scatter(train_Y[:, 0], train_Y[:, 1], alpha=0.5, s=50, label=\"All points\")\n",
    "if pareto_Y.shape[0] > 0:\n",
    "    # Sort for visualization\n",
    "    sort_idx = torch.argsort(pareto_Y[:, 0])\n",
    "    pareto_sorted = pareto_Y[sort_idx]\n",
    "    ax.plot(pareto_sorted[:, 0], pareto_sorted[:, 1], \"r-o\", markersize=8, linewidth=2, label=\"Pareto front\")\n",
    "\n",
    "ax.set_xlabel(\"Objective 1\", fontsize=12)\n",
    "ax.set_ylabel(\"Objective 2\", fontsize=12)\n",
    "ax.set_title(\"Current Pareto Front\", fontsize=14, fontweight=\"bold\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: STCH-qPMHI vs Other Approaches\n",
    "\n",
    "| Approach | Stage 1 | Stage 2 | Best For |\n",
    "|----------|---------|---------|----------|\n",
    "| **STCH-qPMHI** (ours) | STCH scalarization | qPMHI ranking | Continuous MOBO, no generative model needed |\n",
    "| **Generative qPMHI** (paper) | Generative model (VAE/GAN) | qPMHI ranking | Discrete/molecular design, with generative model |\n",
    "| **qNEHVI** | Direct optimization | Hypervolume improvement | Small batches, exact hypervolume |\n",
    "| **qParEGO** | Random weights | Scalarized optimization | Single-objective scalarization |\n",
    "\n",
    "See README.md for detailed comparison and when to use each approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated the STCH-qPMHI two-stage framework:\n",
    "\n",
    "1. **STCH Candidate Generation**: Uses gradient-based STCH scalarization with multiple weight vectors to generate diverse candidate pool\n",
    "2. **qPMHI Batch Selection**: Uses probability of maximum hypervolume improvement to rank and select optimal batch\n",
    "\n",
    "**Key Takeaways:**\n",
    "- STCH-qPMHI combines efficient exploration (STCH) with optimal batch selection (qPMHI)\n",
    "- Works for continuous optimization problems without requiring generative models\n",
    "- Provides both Pareto coverage guarantees and hypervolume optimality\n",
    "- qPMHI algorithm from Muthyala et al. (2025) - properly cited\n",
    "\n",
    "For complete implementation and usage examples, see the README.md and the `stch_botorch.integration` module (when available)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
